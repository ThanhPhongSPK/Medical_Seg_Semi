{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import argparse\n",
    "import torch\n",
    "import cv2\n",
    "import seaborn as sns\n",
    "import random\n",
    "import numpy as np\n",
    "\n",
    "from torchvision import transforms\n",
    "from torch.utils.data import DataLoader\n",
    "import torch.nn.functional as F\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### UNet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "from unet import UNet\n",
    "from dataset import BaseDataSets, RandomGenerator, TwoStreamBatchSampler"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Arguements"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Params \n",
    "class params: \n",
    "    def __init__(self): \n",
    "        self.root_dir = '/kaggle/input/acdc-dataset/ACDC'\n",
    "        self.saved_path = ''\n",
    "        self.exp = 'BCP' \n",
    "        self.model = 'unet' \n",
    "        self.pretrain_iterations = 200\n",
    "        \n",
    "        self.selftrain_iterations = 200\n",
    "        self.batch_size = 24\n",
    "        self.deterministic = 1 \n",
    "        self.base_lr = 0.01 \n",
    "        self.patch_size = [256,256] \n",
    "        self.seed = 42 \n",
    "        self.num_classes = 4 \n",
    "        self.stage_name = 'selftrain'\n",
    "\n",
    "        # label and unlabel \n",
    "        self.labeled_bs = 2\n",
    "        self.label_num = 7 \n",
    "        self.u_weight = 0.5 \n",
    "\n",
    "        # Cost \n",
    "        self.gpu = '0' \n",
    "        self.consistency = 0.1\n",
    "        self.consistency_rampup = 200.0 \n",
    "        self.magnitude = '6.0' \n",
    "        self.s_param = 6 \n",
    "\n",
    "\n",
    "args = params()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def net_factory(net_type=\"unet\", in_chns=1, class_num=2, mode = \"train\", tsne=0):\n",
    "    if net_type == \"unet\" and mode == \"train\":\n",
    "        net = UNet(in_chns=in_chns, class_num=class_num).cuda()\n",
    "    return net"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_name = [\"BCP\"]\n",
    "BCP_model_path = args.saved_path + f'labeled_{args.label_num}/BCP.pth'\n",
    "\n",
    "limit_pixels = 500\n",
    "# Why 0.5?: Likely chosen empirically as a balance between smoothness and detail.\n",
    "bandwidth_adjust = 0.5 \n",
    "line_wid = 5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_ACDC_masks(output):\n",
    "    probs = F.softmax(output, dim=1)\n",
    "    _, probs = torch.max(probs, dim=1)\n",
    "    return probs\n",
    "\n",
    "def patients_to_slices(dataset, patients_num)\n",
    "    ref_dict = None\n",
    "    if \"ACDC\" in dataset:\n",
    "        ref_dict = {\"1\": 32, \"3\": 68, \"7\": 136,\n",
    "                    \"14\": 256, \"21\": 396, \"28\": 512, \"35\": 664, \"70\": 1312}\n",
    "    elif \"Prostate\":\n",
    "        ref_dict = {\"2\": 27, \"4\": 53, \"8\": 120,\n",
    "                    \"12\": 179, \"16\": 256, \"21\": 312, \"42\": 623}\n",
    "    else: \n",
    "        print(\"Error\")\n",
    "    return ref_dict[str(patients_num)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_kde(BCP_feature, BCP_pred, labels, specific_c, f_dim, pic_num):\n",
    "    total_pixel, total_fdim = BCP_feature.shape[0], BCP_feature.shape[1]\n",
    "    labeled_pixel = int(total_pixel / 2) + 1\n",
    "    save_path = f\"KDE/ACDC/{f_dim}/labeled_{args.label_num}/class_{specific_c}\"\n",
    "    if not os.path.exists(save_path):\n",
    "        os.makedirs(save_path)\n",
    "    \n",
    "    # Choose the specific class\n",
    "    l_pred = np.where(BCP_pred[:labeled_pixel, :]==specific_c)\n",
    "    u_pred = np.where(BCP_pred[labeled_pixel:, :]==specific_c)\n",
    "    \n",
    "    l_lab = np.where(labels[:labeled_pixel, :]==specific_c)\n",
    "    u_lab = np.where(BCP_pred[labeled_pixel:, :]==specific_c)\n",
    "    \n",
    "    correct_cor_l = np.intersect1d(l_pred[0], l_lab[0])\n",
    "    correct_cor_u = np.intersect1d(u_pred[0], u_lab[0]) + labeled_pixel\n",
    "    \n",
    "    pixel_num = min(len(correct_cor_l), len(correct_cor_u), limit_pixels)\n",
    "    \n",
    "    print(f\"Total {pixel_num} pixels for class {specific_c}\")\n",
    "    BCP_feature_l = np.mean(BCP_feature[correct_cor_l[:pixel_num]], axis=1)\n",
    "    BCP_feature_u = np.mean(BCP_feature[correct_cor_u[:pixel_num]], axis=1)\n",
    "    \n",
    "    method_name_list = [\"BCP\"]\n",
    "    feature_list = [BCP_feature_l, BCP_feature_u]\n",
    "    \n",
    "    plt.figure()\n",
    "    fig = plt.figure(figsize=(29, 4))\n",
    "    sns.set_context(\"notebook\", font_scale=2)\n",
    "    \n",
    "    for i in range(0, 1):\n",
    "        plt.subplot(1, 1, i+1)\n",
    "        plt.subplots_adjust(left=None, bottom=None, right=None, top=None, \n",
    "                            wspace=0.3, hspace=None)\n",
    "        sns.kdeplot(feature_list[0], bw_adjust=bandwidth_adjust, color='g', line_width=line_wid)\n",
    "        sns.kdeplot(feature_list[1], bw_adjust=bandwidth_adjust, color='b', line_width=line_wid)\n",
    "        plt.xticks(size=16)\n",
    "        plt.yticks(size=16)\n",
    "        plt.ylabel(\" \")\n",
    "        plt.title(method_name_list[i])\n",
    "        \n",
    "    plt.savefig(f\"KDE/ACDC/{f_dim}/labeled_{args.label_num}/class_{specific_c}/kde_test_mean{pic_num}_{args.label_num}_{specific_c}.png\")\n",
    "    print(f\"Save to: KDE/ACDC/{f_dim}/labeled_{args.label_num}/class_{specific_c}/kde_test_mean{pic_num}_{args.label_num}_{specific_c}.png\")\n",
    "    plt.clf()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def Inference(args):\n",
    "    os.environ['CUDA_VISIBLE_DEVICES'] = args.gpu\n",
    "    BCP_Net = net_factory(net_type=args.model, in_chns=1, class_num=args.num_classes, mode=\"test\")\n",
    "    \n",
    "    BCP_Net.load_state_dict(torch.load(BCP_model_path))\n",
    "    print(\"Init models' weight successfully\")\n",
    "    BCP_Net.eval()\n",
    "    \n",
    "    def worker_init_fn(worker_id):\n",
    "        random.seed(1337 + worker_id)\n",
    "    \n",
    "    db_train = BaseDataSets(base_dir=args.root_dir,\n",
    "                            split='train',\n",
    "                            num=None,\n",
    "                            transform=transforms.Compose([RandomGenerator(args.patch_size)]))\n",
    "    total_slices = len(db_train)\n",
    "    labeled_slice = patients_to_slices(args.root_dir, args.label_num)\n",
    "    print(\"Total slices is: {}, labeled slices is:{}\".format(total_slices, labeled_slice))\n",
    "    labeled_idx = list(range(0, labeled_slice))\n",
    "    unlabeled_idxs = list(range(labeled_slice, total_slices))\n",
    "    batch_sampler = TwoStreamBatchSampler(labeled_idx, unlabeled_idxs, args.batch_size, args.batch_size-args.labeled_bs)\n",
    "    trainloader = DataLoader(db_train, batch_sampler=batch_sampler, num_workers=4, pin_memory=True, worker_init_fn=worker_init_fn)\n",
    "    picture_number = 0\n",
    "    \n",
    "    for epoch in range(3):\n",
    "        for _, sampled_batch in enumerate(trainloader):\n",
    "            \n",
    "            volume_batch, label_batch = sampled_batch['image'], sampled_batch['label']\n",
    "            volume_batch, label_batch = volume_batch.cuda(), label_batch.cuda()\n",
    "            label_batch = label_batch.detach().cpu().numpy()\n",
    "            \n",
    "            pred, BCP_feature = BCP_Net(volume_batch)\n",
    "            \n",
    "            B_pred = get_ACDC_masks(pred)\n",
    "            \n",
    "            f_dim, x_, y_ = BCP_feature.shape[1], BCP_feature.shape[2], BCP_feature.shape[3]\n",
    "            BCP_feature = BCP_feature.permute(0, 2, 3, 1).contiguous()\n",
    "            BCP_feature = BCP_feature.view(-1, f_dim) # 1000, 16\n",
    "            \n",
    "            resized_label = np.zeros((args.batch_size, x_, y_))\n",
    "            for i in range(args.batch_size):\n",
    "                resized_label[i,] = cv2.resize(label_batch[i,].squeeze(), (x_, y_))\n",
    "            label_batch = torch.from_numpy(resized_label).cuda()\n",
    "            label = label_batch.view(-1, 1) # a (3, 1) b[a, :]\n",
    "            BCP_pred = B_pred.view(-1, 1)\n",
    "\n",
    "            BCP_feature = BCP_feature.detach().cpu().numpy()\n",
    "            BCP_pred = BCP_pred.detach().cpu().numpy()\n",
    "            label = label.detach().cpu().numpy()\n",
    "            spi_c = 2\n",
    "            plot_kde(BCP_feature, BCP_pred, label, spi_c, f_dim, picture_number)\n",
    "            picture_number += 1"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "phong_env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
