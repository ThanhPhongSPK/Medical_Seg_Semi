{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np \n",
    "import h5py\n",
    "import os \n",
    "import random \n",
    "import itertools\n",
    "import math\n",
    "\n",
    "import torch \n",
    "import torch.nn as nn \n",
    "import torch.nn.functional as F \n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from torch.utils.data.sampler import Sampler\n",
    "from torch.optim import SGD\n",
    "import torchvision.transforms as transforms\n",
    "from skimage.measure import label \n",
    "\n",
    "import torch.backends.cudnn as cudnn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorboardX import SummaryWriter\n",
    "import shutil\n",
    "import argparse\n",
    "import logging\n",
    "import random\n",
    "from medpy import metric\n",
    "import pdb\n",
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Params \n",
    "class params: \n",
    "    def __init__(self):\n",
    "        self.root_path = 'LA'\n",
    "        self.exp = 'BCP' \n",
    "        self.model = 'Unet'\n",
    "        self.pre_max_iterations = 200\n",
    "        self.self_max_iteration = 100 \n",
    "        self.max_samples = 80 \n",
    "        self.labeles_bs = 4\n",
    "        self.bacth_size = 8 \n",
    "        self.base_lr = 0.01 \n",
    "        self.deterministic = 1 \n",
    "        self.labelnum = 8 \n",
    "        self.consistency = 1.0 \n",
    "        self.consistency_rampup = 40.0 \n",
    "        self.magnitude = 10.0 \n",
    "        self.seed = 10\n",
    "    \n",
    "        # Setting of BCP \n",
    "        self.u_weight = 0.5 \n",
    "        self.mask_ratio = 2/3 \n",
    "\n",
    "        # Setting of mixup \n",
    "        self.u_alpha = 2.0 \n",
    "        self.loss_weight = 0.5\n",
    "\n",
    "\n",
    "args = params()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 1. BaseDataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import h5py\n",
    "from torch.utils.data import Dataset\n",
    "\n",
    "class LAHeart(Dataset):\n",
    "    def __init__(self, base_dir, split='train', transform=None, num=None):\n",
    "        self._base_dir = base_dir\n",
    "        self.split = split\n",
    "        self.transform = transform\n",
    "        self.sample_list = []\n",
    "        \n",
    "        # Path for train/test list\n",
    "        list_file = os.path.join(self._base_dir, f\"{split}.list\")\n",
    "        if not os.path.isfile(list_file):\n",
    "            raise ValueError(f\"The {split} list file is missing: {list_file}\")\n",
    "        \n",
    "        with open(list_file, 'r') as file:\n",
    "            self.sample_list = [item.strip() for item in file.readlines()]\n",
    "        \n",
    "        if num is not None:\n",
    "            self.sample_list = self.sample_list[:num]\n",
    "\n",
    "        print(f\"Mode = {self.split}, total samples: {len(self.sample_list)}\")\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.sample_list)\n",
    "\n",
    "    def __getitem__(self, index):\n",
    "        case = self.sample_list[index]\n",
    "        file_path = os.path.join(self._base_dir, f'2018LA_Seg_Training Set/{case}/mri_norm2.h5')\n",
    "        \n",
    "        # Load data safely\n",
    "        try:\n",
    "            with h5py.File(file_path, 'r') as h5f:\n",
    "                image = h5f['image'][:]\n",
    "                label = h5f['label'][:]\n",
    "        except FileNotFoundError:\n",
    "            raise FileNotFoundError(f\"File not found: {file_path}\")\n",
    "        \n",
    "        sample = {'image': image, 'label': label}\n",
    "        if self.transform:\n",
    "            sample = self.transform(sample)\n",
    "        \n",
    "        return sample\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mode = train, total samples: 80\n",
      "Image.shape = (203, 142, 88)\n",
      "Label.shape = (203, 142, 88)\n"
     ]
    }
   ],
   "source": [
    "train_db = LAHeart(\n",
    "    base_dir= 'LA', \n",
    "    split= 'train'\n",
    ")\n",
    "\n",
    "sample =train_db.__getitem__(10)\n",
    "print(f'Image.shape = {sample['image'].shape}')\n",
    "print(f'Label.shape = {sample['label'].shape}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "def random_rot_flip(image, label): \n",
    "    k = np.random.randint(0, 4, 1) \n",
    "    image = np.rot90(image, k) \n",
    "    label = np.rot90(label, k) \n",
    "\n",
    "    axis = np.random.randint(0, 2)\n",
    "    image = np.flip(image, axis) \n",
    "    label = np.flip(label, axis) \n",
    "\n",
    "    return image, label \n",
    "\n",
    "class RandomRotFlip: \n",
    "    def __call__(self, sample): \n",
    "        image, label = sample['image'], sample['label']\n",
    "        image, label = random_rot_flip(image, label) \n",
    "        sample = {'image': image, 'label': label}\n",
    "\n",
    "        return sample "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "class RandomCrop: \n",
    "    def __init__(self, output_size, with_sdf= False): \n",
    "        self.output_size = output_size \n",
    "        self.with_sdf = with_sdf\n",
    "    \n",
    "    def __call__(self, sample): \n",
    "        image, label = sample['image'], sample['label']\n",
    "\n",
    "        if self.with_sdf: \n",
    "            sdf = sample['sdf']\n",
    "        \n",
    "        if label.shape[0] <= self.output_size[0] or label.shape[1] <= self.output_size[1] or label.shape[2] <= self.output_size[2]: \n",
    "            pw = max((self.output_size[0] - label.shape[0]) // 2 + 3, 0) \n",
    "            ph = max((self.output_size[1] - label.shape[1]) // 2 + 3, 0)\n",
    "            pd = max((self.output_size[2] - label.shape[2]) // 2 + 3, 0)\n",
    "            image = np.pad(image, [(pw, pw), (ph, ph),(pd, pd)], mode= 'constant', constant_values= 0)\n",
    "            label = np.pad(label, [(pw, pw), (ph, ph), (pd, pd)], mode= 'constant', constant_values= 0) \n",
    "\n",
    "            if self.with_sdf: \n",
    "                sdf = np.pad(sdf, [(pw, pw), (ph, ph), (pd, pd)], mode= 'constant', constant_values= 0) \n",
    "\n",
    "        (w, h,d) = image.shape \n",
    "        w1 = np.random.randint(0, w - self.output_size[0])\n",
    "        h1 = np.random.randint(0, h - self.output_size[1])\n",
    "        d1 = np.random.randint(0, d - self.output_size[2])\n",
    "    \n",
    "        image = image[w1 : w1 + self.output_size[0], h1 : h1 + self.output_size[1], d1 : d1 + self.output_size[2]]\n",
    "        label = label[w1: w1 + self.output_size[0], h1 : h1 + self.output_size[1], d1 : d1 + self.output_size[2]]\n",
    "\n",
    "        if self.with_sdf: \n",
    "            sdf = sdf[w1 : w1 + self.output_size[0], h1 : h1 + self.output_size[1], d1 : d1 + self.output_size[2]]\n",
    "            return {'image': image, 'label': label, 'sdf': sdf}\n",
    "        else: \n",
    "            return {'image': image, 'label': label}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ToTensor(object):\n",
    "    \n",
    "    def __call__(self, sample):\n",
    "        image = sample['iamge']\n",
    "        image = image.reshape(1, image.shape[0], image.shape[1], image.shape[2]).astype(np.float32)\n",
    "        if 'onehot_label' in sample:\n",
    "            return {'image': torch.from_numpy(image), 'label': torch.from_numpy(sample['label']).long(),\n",
    "                    'onehot_label': torch.from_numpy(sample['onehot_label']).long()}\n",
    "        else:\n",
    "            return {'image': torch.from_numpy(image), 'label': torch.from_numpy(sample['label']).long()}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "def iterate_once(indices): \n",
    "    \"\"\"\n",
    "    Permutate the iterable once \n",
    "    (permutate the labeled_idxs once)\n",
    "    \"\"\"\n",
    "    return np.random.permutation(indices) \n",
    "\n",
    "def iterate_externally(indices): \n",
    "    \"\"\"\n",
    "    Create an infinite iterator that repeatedly permutes the indices.\n",
    "    ( permutate the unlabeled_idxs to make different)\n",
    "    \"\"\"\n",
    "    def infinite_shuffles(): \n",
    "        while True: \n",
    "            yield np.random.permutation(indices)\n",
    "            \n",
    "    return itertools.chain.from_iterable(infinite_shuffles())\n",
    "\n",
    "def grouper(iterable, n): \n",
    "    args = [iter(iterable)] * n \n",
    "    return zip(*args)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "class TwoStreamBatchSampler(Sampler):\n",
    "    def __init__(self, primary_indices, secondary_indices, batch_size, secondary_batch_size):\n",
    "        self.primary_indices = primary_indices\n",
    "        self.secondary_indices = secondary_indices\n",
    "        self.primary_batch_size = batch_size - secondary_batch_size\n",
    "        self.secondary_batch_size = secondary_batch_size\n",
    "        \n",
    "        assert len(self.primary_indices) >= self.primary_batch_size > 0\n",
    "        assert len(self.secondary_indices) >= self.secondary_batch_size > 0\n",
    "        \n",
    "    def __iter__(self):\n",
    "        primary_iter = iterate_once(self.primary_indices)\n",
    "        secondary_iter = iterate_externally(self.secondary_indices)\n",
    "        return (\n",
    "            primary_batch + secondary_batch\n",
    "            for (primary_batch, secondary_batch)\n",
    "            in zip(grouper(primary_iter, self.primary_batch_size),\n",
    "                   grouper(secondary_iter, self.secondary_batch_size))\n",
    "        )\n",
    "        \n",
    "    def __len__(self):\n",
    "        return len(self.primary__indices) // self.primary_batch_size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "def context_mask(img, mask_ratio):\n",
    "    batch_size, channel, img_x, img_y, img_z = img.shape[0], img.shape[1], img.shape[2], img.shape[3], img.shape[4]\n",
    "    loss_mask = torch.ones(batch_size, img_x, img_y, img_z).cuda()\n",
    "    mask = torch.ones(img_x, img_y, img_z).cuda()\n",
    "    patch_pixel_x, patch_pixel_y, patch_pixel_z = int(img_x*mask_ratio), int(img_y*mask_ratio), int(img_z*mask_ratio)\n",
    "    w = np.random.randint(0, 112 - patch_pixel_x)\n",
    "    h = np.random.randint(0, 112 - patch_pixel_y)\n",
    "    z = np.random.randint(0, 80 - patch_pixel_z)\n",
    "    mask[w:w+patch_pixel_x, h:h+patch_pixel_y, z:z+patch_pixel_z] = 0\n",
    "    loss_mask[:, w:w+patch_pixel_x, h:h+patch_pixel_y, z:z+patch_pixel_z] = 0\n",
    "    return mask.long(), loss_mask.long()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "def test_single_case_plus(model_l, model_r, image, stride_xy, stride_z, patch_size, num_classes=1):\n",
    "    w, h, d = image.shape\n",
    "\n",
    "    # if the size of image is less than patch_size, then padding it\n",
    "    add_pad = False\n",
    "    if w < patch_size[0]:\n",
    "        w_pad = patch_size[0]-w\n",
    "        add_pad = True\n",
    "    else:\n",
    "        w_pad = 0\n",
    "    if h < patch_size[1]:\n",
    "        h_pad = patch_size[1]-h\n",
    "        add_pad = True\n",
    "    else:\n",
    "        h_pad = 0\n",
    "    if d < patch_size[2]:\n",
    "        d_pad = patch_size[2]-d\n",
    "        add_pad = True\n",
    "    else:\n",
    "        d_pad = 0\n",
    "    wl_pad, wr_pad = w_pad//2,w_pad-w_pad//2\n",
    "    hl_pad, hr_pad = h_pad//2,h_pad-h_pad//2\n",
    "    dl_pad, dr_pad = d_pad//2,d_pad-d_pad//2\n",
    "    if add_pad:\n",
    "        image = np.pad(image, [(wl_pad,wr_pad),(hl_pad,hr_pad), (dl_pad, dr_pad)], mode='constant', constant_values=0)\n",
    "    ww,hh,dd = image.shape\n",
    "\n",
    "    sx = math.ceil((ww - patch_size[0]) / stride_xy) + 1\n",
    "    sy = math.ceil((hh - patch_size[1]) / stride_xy) + 1\n",
    "    sz = math.ceil((dd - patch_size[2]) / stride_z) + 1\n",
    "    # print(\"{}, {}, {}\".format(sx, sy, sz))\n",
    "    score_map = np.zeros((num_classes, ) + image.shape).astype(np.float32)\n",
    "    cnt = np.zeros(image.shape).astype(np.float32)\n",
    "\n",
    "    for x in range(0, sx):\n",
    "        xs = min(stride_xy*x, ww-patch_size[0])\n",
    "        for y in range(0, sy):\n",
    "            ys = min(stride_xy * y,hh-patch_size[1])\n",
    "            for z in range(0, sz):\n",
    "                zs = min(stride_z * z, dd-patch_size[2])\n",
    "                test_patch = image[xs:xs+patch_size[0], ys:ys+patch_size[1], zs:zs+patch_size[2]]\n",
    "                test_patch = np.expand_dims(np.expand_dims(test_patch,axis=0),axis=0).astype(np.float32)\n",
    "                test_patch = torch.from_numpy(test_patch).cuda()\n",
    "\n",
    "                with torch.no_grad():\n",
    "                    y1_l, _ = model_l(test_patch)\n",
    "                    y1_r, _ = model_r(test_patch)\n",
    "                    y1 = (y1_l + y1_r) / 2\n",
    "                    y = F.softmax(y1, dim=1)\n",
    "\n",
    "                y = y.cpu().data.numpy()\n",
    "                y = y[0,1,:,:,:]\n",
    "                score_map[:, xs:xs+patch_size[0], ys:ys+patch_size[1], zs:zs+patch_size[2]] \\\n",
    "                  = score_map[:, xs:xs+patch_size[0], ys:ys+patch_size[1], zs:zs+patch_size[2]] + y\n",
    "                cnt[xs:xs+patch_size[0], ys:ys+patch_size[1], zs:zs+patch_size[2]] \\\n",
    "                  = cnt[xs:xs+patch_size[0], ys:ys+patch_size[1], zs:zs+patch_size[2]] + 1\n",
    "    score_map = score_map/np.expand_dims(cnt,axis=0)\n",
    "    label_map = (score_map[0]>0.5).astype(np.int)\n",
    "    if add_pad:\n",
    "        label_map = label_map[wl_pad:wl_pad+w,hl_pad:hl_pad+h,dl_pad:dl_pad+d]\n",
    "        score_map = score_map[:,wl_pad:wl_pad+w,hl_pad:hl_pad+h,dl_pad:dl_pad+d]\n",
    "    return label_map, score_map\n",
    "\n",
    "def var_all_case_LA_plus(model_l, model_r, num_classes, patch_size=(112, 112, 80), stride_xy=18, stride_z=4):\n",
    "   \n",
    "    with open('/data/byh_data/SSNet_data/LA/test.list', 'r') as f:\n",
    "        image_list = f.readlines()\n",
    "    image_list = [\"/data/byh_data/SSNet_data/LA/2018LA_Seg_Training Set/\" + item.replace('\\n', '') + \"/mri_norm2.h5\" for item in image_list]\n",
    "    loader = tqdm(image_list)\n",
    "    total_dice = 0.0\n",
    "    for image_path in loader:\n",
    "        h5f = h5py.File(image_path, 'r')\n",
    "        image = h5f['image'][:]\n",
    "        label = h5f['label'][:]\n",
    "        prediction, score_map = test_single_case_plus(model_l, model_r, image, stride_xy, stride_z, patch_size, num_classes=num_classes)\n",
    "        if np.sum(prediction)==0:\n",
    "            dice = 0\n",
    "        else:\n",
    "            dice = metric.binary.dc(prediction, label)\n",
    "        total_dice += dice\n",
    "    avg_dice = total_dice / len(image_list)\n",
    "    print('average metric is {}'.format(avg_dice))\n",
    "    return avg_dice"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 2.Loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "def to_one_hot(tensor, nclasses): \n",
    "    \"\"\"\n",
    "    Input (tensor): Nx1xHxW \n",
    "    \"\"\"\n",
    "    assert tensor.max().item() < nclasses\n",
    "    assert tensor.min().item() >= 0 \n",
    "\n",
    "    size = list(tensor.size())\n",
    "    assert size[1] == 1 \n",
    "    size[1] = nclasses\n",
    "    one_hot = torch.zeros(*size) \n",
    "    if tensor.is_cuda: \n",
    "        one_hot = one_hot.cuda(tensor.device) \n",
    "    one_hot = one_hot.scatter_(1, tensor, 1) \n",
    "    return one_hot \n",
    "\n",
    "def get_probability(logits): \n",
    "    \"\"\"\n",
    "    Get the probability from logitis  \n",
    "    \"\"\"\n",
    "    size = logits.size() \n",
    "    if size[1] > 1: \n",
    "        pred = F.softmax(logits, dim= 1) \n",
    "        nclass = size[1] \n",
    "    else: \n",
    "        pred = F.sigmoid(logits) \n",
    "        pred = torch.cat([1 - pred, pred], dim= 1) \n",
    "    \n",
    "    return pred, nclass\n",
    "\n",
    "\n",
    "class mask_DiceLoss(nn.Module): \n",
    "    def __init__(self, nclass, class_weights = None, smooth= 1e-5): \n",
    "        super(mask_DiceLoss, self).__init__() \n",
    "        self.smooth = smooth \n",
    "        if class_weights is None: \n",
    "            self.class_weights = nn.Parameter(torch.ones((1, nclass)).type(torch.float32), requires_grad= False) \n",
    "        else: \n",
    "            class_weights = np.array(class_weights) \n",
    "            assert nclass == class_weights.shape[0] \n",
    "            self.class_weights = nn.Parameter(torch.tensor(class_weights, dtype= torch.float32), requires_grad= False) \n",
    "    \n",
    "    def prob_forward(self, pred, target, mask= None): \n",
    "        size = pred.size() \n",
    "        N, nclass = size[0], size[1] \n",
    "\n",
    "        # N x C x H x W: convert into 2D image\n",
    "        pred_one_hot = pred.view(N, nclass, -1) \n",
    "        target = target.view(N, 1, -1) \n",
    "        target_one_hot = to_one_hot(target.type(torch.long), nclass).type(torch.float32)\n",
    "\n",
    "        # N x C x H x W\n",
    "        inter = pred_one_hot * target_one_hot\n",
    "        union = pred_one_hot + target_one_hot\n",
    "\n",
    "        if mask is not None: \n",
    "            mask = mask.view(N, 1, -1) \n",
    "            inter = (inter.view(N, nclass, -1) * mask).sum(2) \n",
    "            union = (union.view(N, nclass, -1) * mask).sum(2) \n",
    "        else: \n",
    "            inter = inter.view(N, nclass, -1).sum(2) \n",
    "            union = union.view(N, nclass, -1).sum(2)\n",
    "        \n",
    "        dice = ( 2*inter + self.smooth ) / (union + self.smooth) \n",
    "        return 1 - dice.mean()\n",
    "\n",
    "    def forward(self, logits,target, mask = None): \n",
    "        size = logits.size() \n",
    "        N, nclass = size[0], size[1] \n",
    "\n",
    "        logits = logits.view(N, nclass, -1) \n",
    "        target = target.view(N, 1, -1) \n",
    "\n",
    "        pred, nclass = get_probability(logits) \n",
    "\n",
    "        pred_one_hot = pred \n",
    "        target_one_hot = to_one_hot(target.type(torch.long), nclass).type(torch.float32) \n",
    "\n",
    "        inter = pred_one_hot * target_one_hot\n",
    "        union = pred_one_hot + target_one_hot\n",
    "\n",
    "        if mask is not None: \n",
    "            mask = mask.view(N, 1, -1) \n",
    "            inter = (inter.view(N, nclass, -1) * mask).sum(2)\n",
    "            union = (union.view(N, nclass, -1) * mask ).sum(2) \n",
    "        else: \n",
    "            inter = inter.view(N, nclass, -1).sum(2) \n",
    "            union = union.view(N, nclass, -1).sum(2)\n",
    "        \n",
    "        dice = ( 2 * inter + self.smooth ) / (union + self.smooth)\n",
    "        return 1 - dice.mean() \n",
    "        \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### UNet3D"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.nn import Module, Sequential\n",
    "from torch.nn import Conv3d, ConvTranspose3d, BatchNorm3d, MaxPool3d, AvgPool3d, AvgPool1d, Dropout3d\n",
    "from torch.nn import ReLU, Sigmoid\n",
    "import torch\n",
    "import pdb\n",
    "\n",
    "class UNet(Module):\n",
    "    def __init__(self, in_dimension=1, out_dimension=2, ft_channels=[64, 256, 256, 512, 1024], residual='conv'):\n",
    "        super(UNet, self).__init__()\n",
    "        \n",
    "        # Encoder downsamplers\n",
    "        self.pool1 = MaxPool3d((2, 2, 2))\n",
    "        self.pool2 = MaxPool3d((2, 2, 2))\n",
    "        self.pool3 = MaxPool3d((2, 2, 2))\n",
    "        self.pool4 = MaxPool3d((2, 2, 2))\n",
    "        \n",
    "        # Encoder convolutions\n",
    "        self.conv_block1 = Conv3D_Block(in_dimension, ft_channels[0], residual=residual)\n",
    "        self.conv_block2 = Conv3D_Block(ft_channels[0], ft_channels[1], residual=residual)\n",
    "        self.conv_block3 = Conv3D_Block(ft_channels[1], ft_channels[2], residual=residual)\n",
    "        self.conv_block4 = Conv3D_Block(ft_channels[2], ft_channels[3], residual=residual)\n",
    "        self.conv_block5 = Conv3D_Block(ft_channels[3], ft_channels[4], residual=residual)\n",
    "        \n",
    "        # Decoderr convolutions\n",
    "        self.decoder_conv_block4 = Conv3D_Block(2 * ft_channels[3], ft_channels[3], residual=residual)\n",
    "        self.decoder_conv_block3 = Conv3D_Block(2 * ft_channels[2], ft_channels[2], residual=residual)\n",
    "        self.decoder_conv_block2 = Conv3D_Block(2 * ft_channels[1], ft_channels[1], residual=residual)\n",
    "        self.decoder_conv_block1 = Conv3D_Block(2 * ft_channels[0], ft_channels[0], residual=residual)\n",
    "        \n",
    "        # Decoder upsamplers\n",
    "        self.deconv_block4 = Deconv3D_Block(ft_channels[4], ft_channels[3])\n",
    "        self.deconv_block3 = Deconv3D_Block(ft_channels[3], ft_channels[2])\n",
    "        self.deconv_block2 = Deconv3D_Block(ft_channels[2], ft_channels[1])\n",
    "        self.deconv_block1 = Deconv3D_Block(ft_channels[1], ft_channels[0])\n",
    "        \n",
    "        # Final 1*1 Convolutions segmentation map\n",
    "        self.one_conv = Conv3d(ft_channels[0], out_dimension, kernel_size=1, stride=1, padding=0, bias=True)\n",
    "        \n",
    "        # Activation function\n",
    "        self.sigmoid = Sigmoid()\n",
    "        \n",
    "    def forward(self, x):\n",
    "        \n",
    "        # Encoder part\n",
    "        x1 = self.conv_block1(x)\n",
    "        x_low1 = self.pool1(x1)\n",
    "        \n",
    "        x2 = self.conv_block2(x_low1)\n",
    "        x_low2 = self.pool2(x2)\n",
    "        \n",
    "        x3 = self.conv_block3(x_low2)\n",
    "        x_low3 = self.pool3(x3)\n",
    "        \n",
    "        x4 = self.conv_block4(x_low3)\n",
    "        x_low4 = self.pool4(x4)\n",
    "        \n",
    "        base = self.conv_block5(x_low4)\n",
    "        \n",
    "        # Decoder part\n",
    "        d4 = torch.cat([self.deconv_block4(base), x4], dim=1)\n",
    "        d_high4 = self.decoder_conv_block4(d4)\n",
    "        \n",
    "        d3 = torch.cat([self.deconv_block3(d_high4), x3], dim=1)\n",
    "        d_high3 = self.decoder_conv_block3(d3)\n",
    "        d_high3 = Dropout3d(p=0.05)(d_high3)\n",
    "        \n",
    "        d2 = torch.cat([self.deconv_block2(d_high3), x2], dim=1)\n",
    "        d_high2 = self.decoder_conv_block2(d2)\n",
    "        d_high2 = Dropout3d(p=0.05)(d_high2)\n",
    "        \n",
    "        d1 = torch.cat([self.deconv_block1(d_high2), x1], dim=1)\n",
    "        d_high1 = self.decoder_conv_block1(d1)\n",
    "        \n",
    "        seg = self.one_conv(d_high1)\n",
    "        \n",
    "        return seg\n",
    "\n",
    "        \n",
    "class Conv3D_Block(Module):\n",
    "    def __init__(self, in_features, out_features, kernel=3, stride=1, padding=1, residual=None):\n",
    "        super(Conv3D_Block, self).__init__()\n",
    "        \n",
    "        self.conv1 = Sequential(\n",
    "            Conv3d(in_features, out_features, kernel_size=kernel, stride=stride, padding=padding, bias=True),\n",
    "            BatchNorm3d(out_features),\n",
    "            ReLU()\n",
    "        )\n",
    "        \n",
    "        self.conv2 = Sequential(\n",
    "            Conv3d(out_features, out_features, kernel_size=kernel, stride=stride, padding=padding, bias=True),\n",
    "            BatchNorm3d(out_features),\n",
    "            ReLU()\n",
    "        )\n",
    "        \n",
    "        self.residual = residual\n",
    "        \n",
    "        if self.residual is not None:\n",
    "            self.residual_upsampler = Conv3d(in_features, out_features, kernel_size=1, bias=False)\n",
    "            \n",
    "    def forward(self, x):\n",
    "        \n",
    "        res = x\n",
    "        \n",
    "        if not self.residual:\n",
    "            return self.conv2(self.conv1(x))\n",
    "        else:\n",
    "            return self.conv2(self.conv1(x)) + self.residual_upsampler(res)\n",
    "        \n",
    "class Deconv3D_Block(Module):\n",
    "    \n",
    "    def __init__(self, in_features, out_features, kernel=3, stride=2, padding=1):\n",
    "        super(Deconv3D_Block, self).__init__()\n",
    "        \n",
    "        self.deconv = Sequential(\n",
    "            ConvTranspose3d(in_features, out_features, kernel_size=(kernel, kernel, kernel),\n",
    "                            stride=(stride, stride, stride), padding=(padding, padding, padding), output_padding=1, bias=True),\n",
    "            ReLU()\n",
    "        )\n",
    "        \n",
    "    def forward(self, x):\n",
    "        return self.deconv(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sigmoid_rampup(current, rampup_length):\n",
    "    if rampup_length == 0: \n",
    "        return 1.0 \n",
    "    else:\n",
    "        current = np.clip(current, 0, rampup_length)\n",
    "        phase = 1 - (current / rampup_length)\n",
    "        return float(np.exp(-5 * phase * phase))\n",
    "    \n",
    "# Mean-Teacher compomnent \n",
    "def get_current_consistency_weight(epoch, args): \n",
    "    return 5 * args.consistency + sigmoid_rampup(epoch, args.consistency_rampup)\n",
    "\n",
    "def update_model_ema(model, ema_model, alpha): \n",
    "    model_state = model.state_dict() \n",
    "    model_ema_state = ema_model.state_dict()\n",
    "\n",
    "\n",
    "    new_dict = {} \n",
    "\n",
    "    for key in model_state:\n",
    "        new_dict[key] = alpha * model_ema_state[key] + (1 - alpha) * model_state[key]\n",
    "\n",
    "    ema_model.load_state_dict(new_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_cut_mask(out, thres=0.5, nms=0):\n",
    "    probs = F.softmax(out, 1)\n",
    "    masks = (probs >= thres).type(torch.int64)\n",
    "    masks = masks[:, 1, :, :].contiguous()\n",
    "    if nms == 1:\n",
    "        masks = LargestCC_pancreas(masks)\n",
    "    return masks\n",
    "\n",
    "def LargestCC_pancreas(segmentation):\n",
    "    N = segmentation.shape[0]\n",
    "    batch_list = []\n",
    "    for n in range(N):\n",
    "        n_prob = segmentation[n].detach().cpu().numpy()\n",
    "        labels = label(n_prob)\n",
    "        if labels.max() != 0:\n",
    "            largestCC = labels == np.argmax(np.bincount(labels.flat)[1:])+1\n",
    "        else:\n",
    "            largestCC = n_prob\n",
    "        batch_list.append(largestCC)\n",
    "    \n",
    "    return torch.Tensor(batch_list).cuda()\n",
    "\n",
    "def save_net_opt(net, optimizer, path):\n",
    "    state = {\n",
    "        'net': net.state_dict(),\n",
    "        'opt': optimizer.state_dict(),\n",
    "    }\n",
    "    torch.save(state, str(path))\n",
    "\n",
    "def load_net_opt(net, optimizer, path):\n",
    "    state = torch.load(str(path))\n",
    "    net.load_state_dict(state['net'])\n",
    "    optimizer.load_state_dict(state['opt'])\n",
    "\n",
    "def load_net(net, path):\n",
    "    state = torch.load(str(path))\n",
    "    net.load_state_dict(state['net'])\n",
    "\n",
    "def get_current_consistency_weight(epoch):\n",
    "    return args.consistency * sigmoid_rampup(epoch, args.consistency_rampup)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "def net_factory(net_type=\"unet\", in_channels=1, class_num=2, mode=\"train\", tse=0):\n",
    "    if net_type == \"unet\" and mode == \"train\":\n",
    "        net = UNet(in_channels, class_num, mode).cuda()\n",
    "        \n",
    "    return net"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data_path = args.root_path \n",
    "pre_max_iterations = args.pre_max_iterations\n",
    "self_max_iterations = args.self_max_iteration \n",
    "base_lr = args.base_lr \n",
    "CE = nn.CrossEntropyLoss(reduction= 'none')\n",
    "\n",
    "\n",
    "if args.deterministic:\n",
    "    cudnn.benchmark = False\n",
    "    cudnn.deterministic = True\n",
    "    torch.manual_seed(args.seed)\n",
    "    torch.cuda.manual_seed(args.seed)\n",
    "    random.seed(args.seed)\n",
    "    np.random.seed(args.seed)\n",
    "\n",
    "patch_size = (112, 112, 80)\n",
    "num_classes = 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "def pre_train(args, snapshot_path):\n",
    "    model = net_factory(args.model, in_channels=1, class_num=num_classes, mode=\"train\")\n",
    "    db_train = LAHeart(base_dir=train_data_path, \n",
    "                       split='train',\n",
    "                       transform=transforms.Compose([\n",
    "                           RandomRotFlip(),\n",
    "                           RandomCrop(patch_size),\n",
    "                           ToTensor(),\n",
    "                       ]))\n",
    "    labelnum = args.labelnum\n",
    "    labeled_idxs = list(range(labelnum))\n",
    "    unlabeled_idxs = list(range(labelnum, args.max_samples))\n",
    "    batch_sampler = TwoStreamBatchSampler(labeled_idxs, unlabeled_idxs, args.batch_size, args.batch_size-args.labeled_bs)\n",
    "    sub_bs = int(args.labeled_bs/2)\n",
    "    def worker_init_fn(worker_id):\n",
    "        random.seed(args.seed+worker_id)\n",
    "    trainloader = DataLoader(db_train, batch_sampler=batch_sampler, num_workers=4, pin_memory=True, worker_init_fn=worker_init_fn)\n",
    "    optimizer = SGD(model.parameters(), lr=base_lr, momentum=0.9, weight_decay=1e-4)\n",
    "    DICE = mask_DiceLoss(nclass=2)\n",
    "    \n",
    "    model.train()\n",
    "    writer = SummaryWriter(snapshot_path + '/log')\n",
    "    logging.info(\"{} iterations per epoch\".format(len(trainloader)))\n",
    "    iter_num = 0\n",
    "    best_dice = 0\n",
    "    max_epoch = pre_max_iterations // len(trainloader) + 1\n",
    "    iterator = tqdm(range(max_epoch), ncols=70)\n",
    "    for epoch_num in iterator:\n",
    "        for _, sampled_batch in enumerate(trainloader):\n",
    "            volume_batch, label_batch = sampled_batch['image'][:args.labeled_bs], sampled_batch['label'][:args.labeled_bs]\n",
    "            volume_batch, label_batch = volume_batch.cuda(), label_batch.cuda()\n",
    "            img_a, img_b = volume_batch[:sub_bs], volume_batch[sub_bs:]\n",
    "            lab_a, lab_b = label_batch[:sub_bs], label_batch[sub_bs:]\n",
    "            \n",
    "            with torch.no_grad():\n",
    "                img_mask, loss_mask = context_mask(img_a, args.mask_ratio)\n",
    "                \n",
    "            # Mix Input\n",
    "            volume_batch = img_a * img_mask + img_b * (1 - img_mask)\n",
    "            label_batch = lab_a * img_mask + lab_b * (1 - img_mask)\n",
    "            \n",
    "            outputs, _ = model(volume_batch)\n",
    "            loss_ce = F.cross_entropy(outputs, label_batch)\n",
    "            loss_dice = DICE(outputs, label_batch)\n",
    "            loss = (loss_ce + loss_dice) / 2\n",
    "            \n",
    "            iter_num += 1\n",
    "            writer.add_scalar('pre/loss_dice', loss_dice, iter_num)\n",
    "            writer.add_scalar('pre/loss_ce', loss_ce, iter_num)\n",
    "            writer.add_scalar('pre/loss_all', loss, iter_num)\n",
    "            \n",
    "            optimizer.zero_grad()\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            logging.info('iteration %d : loss: %03f, loss_dice: %03f, loss_ce: %03f' %(iter_num, loss, loss_dice, loss_ce))\n",
    "            \n",
    "            if iter_num >= pre_max_iterations:\n",
    "                break\n",
    "\n",
    "        if iter_num >= pre_max_iterations:\n",
    "            iterator.close()\n",
    "            break\n",
    "    writer.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "phong_env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
