{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np \n",
    "import pandas as pd \n",
    "import matplotlib.pyplot as plt \n",
    "\n",
    "import torch \n",
    "from torch.utils.data import DataLoader\n",
    "from medpy import metric \n",
    "from scipy.ndimage import zoom \n",
    "\n",
    "from dataset.basedataset import BaseDataset\n",
    "from networks.UNet2D import UNet_2d\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total slies: 20\n",
      "Image.shape = torch.Size([1, 10, 256, 224])\n",
      "Label.shape = torch.Size([1, 10, 256, 224])\n"
     ]
    }
   ],
   "source": [
    "db_val = BaseDataset(\n",
    "    root_path= 'ACDC', \n",
    "    split= 'val'\n",
    ")\n",
    "\n",
    "print(f'Total slies: {len(db_val)}')\n",
    "\n",
    "# create dataloader \n",
    "valloader = DataLoader(db_val, batch_size= 1, shuffle= False) \n",
    "dataiter = iter(valloader) \n",
    "volume_batches = next(dataiter) \n",
    "image, label = volume_batches['image'], volume_batches['label']\n",
    "print(f'Image.shape = {image.shape}')\n",
    "print(f'Label.shape = {label.shape}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "#TODO: should I have a threshold \n",
    "def calculalte_metric_percase(pred, gt): \n",
    "    pred[pred > 0] = 1 \n",
    "    gt[gt > 0] = 1 \n",
    "\n",
    "    if pred.sum() > 0: \n",
    "        dice = metric.binary.dc(pred, gt) \n",
    "        hd95 = metric.binary.hd95(pred, gt) \n",
    "        return dice, hd95\n",
    "    else: \n",
    "        return 0, 0 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "def test_single_volume(image, label, model, classes, patch_size = [256,256]):\n",
    "    \"\"\"\n",
    "    Use to validate ACDC dataset \n",
    "    1. Valid for 2D image. Shape = (1, H, W)\n",
    "    2. Valid metric = [dice, hd95]\n",
    "    Params: \n",
    "        - image (torch.Tensor): valid image. Shape = (1, num_slices, H, W) \n",
    "        - label (torch.Tensor): valid label. Shape = (1, num_slices, H, W) \n",
    "\n",
    "    \"\"\" \n",
    "    image = image.squeeze(0).cpu().detach().numpy() \n",
    "    label = label.squeeze(0).cpu().detach().numpy() # label.shape = (n_slices, H, W), label.range = range(0, 4)\n",
    "\n",
    "    prediction = np.zeros_like(label) # shape = (n_slices, H, W) \n",
    "    for ind in range(image.shape[0]): \n",
    "        slice = image[ind, :, :] # shape = (image.H, image.W) \n",
    "\n",
    "        # zoom \n",
    "        x, y = slice.shape[0], slice.shape[1] \n",
    "        slice = zoom(slice, (patch_size[0] / x, patch_size[1] / y), order= 0)\n",
    "        \n",
    "        # Evaluate\n",
    "        input = torch.from_numpy(slice).unsqueeze(0).unsqueeze(0).float().cuda() # (1, 1, 256, 256) \n",
    "        model.eval() \n",
    "        with torch.no_grad(): \n",
    "            output = model(input) # output.shape = (1, 3, 256, 256) with n_classes = 3 - logits \n",
    "            if len(output) > 1: \n",
    "                output = output[0] \n",
    "            \n",
    "            out = torch.argmax(torch.softmax(output, dim= 1), dim= 1).squeeze(0)  # out.shape = (256, 256), probabilites\n",
    "            out = out.cpu().detach().numpy() \n",
    "            pred = zoom(out, (x / patch_size[0], y / patch_size[1]), order= 0) \n",
    "            prediction[ind] = pred \n",
    "    \n",
    "    metric_list = [] \n",
    "    for i in range(1, classes): \n",
    "        metric_list.append(calculalte_metric_percase(prediction == i, label == i))\n",
    "    \n",
    "    return metric_list\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(0, 0), (0, 0), (0.017284450045726516, 142.23923509355637)]"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = UNet_2d(in_chns=1, class_num= 4).cuda()\n",
    "metric_list = test_single_volume(image, label, model, classes= 4)\n",
    "metric_list"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 2. Valid 3D "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "DeepLearning",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
